# -*- coding: utf-8 -*-
"""recommender-system.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1slVSQI3HF_Y93ubmAt9vB8UtbGLi59dr

# Import Library yang Digunakan
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

"""# Load kaggle api"""

# Upload kaggle.json
from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

"""# Data Understanding"""

!kaggle datasets download -d nicoletacilibiu/movies-and-ratings-for-recommendation-system -p /kaggle

"""unzip dataset"""

!unzip /kaggle/movies-and-ratings-for-recommendation-system.zip -d /kaggle

"""konversi data movies ke dalam dataframe"""

movies_df = pd.read_csv('/kaggle/movies.csv', on_bad_lines='skip')
movies_df.head()

"""konversi data ratings ke dalam dataframe"""

ratings_df = pd.read_csv('/kaggle/ratings.csv', on_bad_lines='skip')
ratings_df.head()

"""cek variabel"""

movies_df.info()

"""insight :
- terdapat 9742 baris data di dalam dataset
- data terdiri dari 3 kolom yaitu : movieId, title, dan genres.
- terdapat 1 data bertipe int64 yaitu kolom movieId, dan 2 kolom bertipe object yaitu kolom title dan genres
"""

ratings_df.info()

"""insight :
- terdapat 100836 baris data di dalam dataset
- data terdiri dari 4 kolom yaitu : userId,movieId, rating, dan timestamp.
- terdapat 3 data bertipe int64 yaitu kolom user_id dan movieId, dan 1 kolom bertipe float64 yaitu kolom rating
"""

# cek jumlah data
print('Jumlah data movies: ',len(movies_df.movieId.unique()))
print('Jumlah data user: ',len(ratings_df.userId.unique()))

"""berdasarkan data understanding yang telah dilakukan, data ratings_df tidak diperlukan untuk membuat content based filtering recommender system

# Univariate Exploratory Data Analysis

## Memeriksa Missing Value
"""

missing_values_movie = movies_df.isnull().sum()
print('jumlah missing value pada data movie: ', missing_values_movie)

missing_values_rating = ratings_df.isnull().sum()
print('jumlah missing value pada data rating: ', missing_values_rating)

"""insight :
- tidak ditemukan missing value di dalam data

## Memeriksa Outlier
"""

sns.set(style="whitegrid")

# Buat figure boxplot
plt.figure(figsize=(8, 5))
sns.boxplot(x=ratings_df['rating'], color='skyblue')

# Judul dan label
plt.title('Distribusi Rating Film (Boxplot)', fontsize=14)
plt.xlabel('Rating')

# Tampilkan plot
plt.show()

"""insight :  
- tidak ditemukan outlier di dalam data

## Memeriksa data duplikat
"""

# jumlah data duplikat pada data movie
jumlah_duplikat_movie = movies_df.duplicated().sum()
print('Jumlah data duplikat pada data movie: ', jumlah_duplikat_movie)

# jumlah data duplikat pada data rating
jumlah_duplikat_rating = ratings_df.duplicated().sum()
print('Jumlah data duplikat pada data rating', jumlah_duplikat_rating)

"""insight :
- tidak ditemukan data duplikat

## Univariate Analysis
"""

# cek daftar genre
all_genres = movies_df['genres'].str.split('|').explode()

unique_genres = all_genres.unique()
print('Jumlah genre unik:', len(unique_genres))
print('Daftar genre unik:')
for genre in unique_genres:
    print('-', genre)

"""cek jumlah setiap genre"""

# Visualisasi jumlah genre
genre_counts = all_genres.value_counts()

# Tampilkan  genre terbanyak
print("Genre terbanyak:\n")
print(genre_counts)
# Visualisasi dengan barplot
plt.figure(figsize=(12, 6))
sns.barplot(x=genre_counts.values, y=genre_counts.index, palette='viridis')

plt.title('Genre dalam Dataset')
plt.xlabel('Jumlah Film')
plt.ylabel('Genre')
plt.tight_layout()
plt.show()

"""insight :
- terdapat 20 genre unik di dalam dataset.
- Drama adalah genre yang paling banyak muncul, diikuti oleh Comedy dan Thriller.
- Genre seperti Film-Noir dan Western tergolong langka.
- Terdapat 34 film tanpa genre yang tercantum, sehingga perlu dilakukan penghapusan karena model content based filtering yang akan dibangun berdasarkan genre.

# Data Preprocessing

## Data movie
"""

# Hapus baris yang kolom 'genres' berisi '(no genres listed)'
fix_movie = movies_df[movies_df['genres'] != '(no genres listed)'].copy()

# Cek hasil
print(f"Sebelum: {len(movies_df)} baris")
print(f"Setelah: {len(fix_movie)} baris")

"""konversi data ke dalam list"""

# mengonversi setiap data series 'movieId' menjadi bentuk list
moviesId = fix_movie['movieId'].tolist()

# mengonversi data 'title' menjadi bentuk list
title = fix_movie['title'].tolist()

# mengonversi data 'genres' menjadi bentuk list
genres = fix_movie['genres'].tolist()

print(len(moviesId))
print(len(title))
print(len(genres))

"""Membuat dictionary untuk data ‘moviesId’, ‘title’, dan ‘genres’"""

movies_new = pd.DataFrame({
    'moviesId': moviesId,
    'title': title,
    'genres': genres
})
movies_new

"""# Model Deployment"""

# membuat salinan dari data movies
data_movies = fix_movie.copy()

"""### TF_IDF Vectorizer"""

# Inisialisasi TfidfVectorizer
tfidf = TfidfVectorizer(stop_words='english')

tfidf_matrix = tfidf.fit_transform(data_movies['genres'])

tfidf.get_feature_names_out()

"""insight
- Mengubah teks genre menjadi vektor numerik untuk mengubah setiap kumpulan genre (contohnya "Action|Adventure|Fantasy") menjadi vektor berdasarkan bobot TF-IDF (Term Frequency-Inverse Document Frequency).

menampilkan dimensi (ukuran) dari matriks TF-IDF
"""

tfidf_matrix.shape

"""Mengubah matrix TF-IDF dari format sparse menjadi format dense agar dapat diproses atau ditampilkan secara lengkap."""

tfidf_matrix.todense()

"""memvisualisasikan sebagian data TF-IDF hasil ekstraksi"""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tfidf.get_feature_names_out(),
    index=data_movies['title']
).sample(20, axis=1).sample(10, axis=0)

"""menggunakan subset 1000 film pertama untuk menghemat ram"""

tfidf_sample = tfidf_matrix[:1000]
cosine_sim_sample = cosine_similarity(tfidf_sample)
cosine_sim_sample

"""insight

- Menghitung similarity antar film berdasarkan fitur TF-IDF dari deskripsi atau metadata film.

- Mengurangi penggunaan memori dan mempercepat perhitungan dengan membatasi data hanya pada 1000 film pertama, karena menghitung similarity untuk seluruh dataset bisa sangat berat dan lambat jika dataset besar.

membuat DataFrame dari hasil perhitungan cosine similarity antar film
"""

cosine_sim_df = pd.DataFrame(
    cosine_sim_sample,
    index=data_movies['title'][:1000],
    columns=data_movies['title'][:1000]
)

print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""membangun model content based filtering"""

def movie_recommendations(title, similarity_data=cosine_sim_df, items=data_movies[['title', 'genres']], k=5):
    if title not in similarity_data.columns:
        return f"Film '{title}' tidak ditemukan dalam data."

    index = similarity_data.loc[:, title].to_numpy().argpartition(range(-1, -k, -1))
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    closest = closest.drop(title, errors='ignore')
    return pd.DataFrame({'title': closest}).merge(items, on='title').head(k)

"""cek salah satu judul filem untuk di tes"""

data_movies[data_movies.title.eq('Jumanji (1995)')]

"""mencoba melihat rekomendasi berdasarkan film 'Jumanji (1995)'"""

movie_recommendations('Jumanji (1995)')

"""# Evauation

** Precision**
**Precision** adalah matriks evaluasi kinerja model sistem rekomendasi yang mengukur seberapa banyak rekomendasi yang diberikan oleh sistem benar-benar relevan atau sesuai dengan preferensi pengguna. Secara matematis :

$$
\text{Precision} = \frac{\text{Jumlah item relevan yang direkomendasikan}}{\text{Jumlah total item yang direkomendasikan}}
$$

#### Alasan Memilih Precision sebagai Metrik Evaluasi

1. Fokus pada kualitas rekomendasi yang diberikan

   Precision menilai seberapa tepat rekomendasi yang muncul. Dalam konteks content-based filtering, rekomendasi yang akurat sangat penting agar pengguna merasa puas dan sistem dianggap bermanfaat.

2. Mudah dipahami dan diinterpretasikan

   Precision memberikan gambaran langsung berapa banyak rekomendasi yang benar-benar relevan dibanding total rekomendasi yang diberikan. Nilai precision yang tinggi menunjukkan kualitas rekomendasi yang baik.

3. Relevan untuk kasus rekomendasi dengan daftar terbatas

   Dalam banyak kasus, sistem rekomendasi hanya menampilkan sejumlah kecil item (misal top 5 atau top 10). Precision cocok digunakan untuk menilai performa dalam skala kecil tersebut.

4. Tidak bergantung pada total jumlah item relevan di database

   Berbeda dengan recall yang membutuhkan data lengkap tentang semua item relevan, precision hanya fokus pada hasil rekomendasi yang muncul. Ini memudahkan evaluasi terutama ketika data lengkap sulit diketahui.

#### Kesimpulan

Precision adalah metrik yang tepat digunakan untuk mengevaluasi sistem rekomendasi content-based filtering karena memberikan informasi jelas tentang proporsi rekomendasi yang benar-benar relevan bagi pengguna. Dengan memaksimalkan precision, kita dapat meningkatkan kepuasan pengguna terhadap rekomendasi yang diberikan.

---
"""

# Fungsi cek relevansi berdasarkan kesamaan genre
def is_relevant(genre_str, target_genres):
    genres = set(genre_str.split('|'))
    return target_genres.issubset(genres)

# Fungsi utama: hitung precision berdasarkan judul film
def evaluate_precision_by_title(movie_title):
    # cari genre dari film input
    movie_row = data_movies[data_movies['title'] == movie_title]

    if movie_row.empty:
        print(f"Film '{movie_title}' tidak ditemukan.")
        return

    target_genres = set(movie_row.iloc[0]['genres'].split('|'))

    # ambil rekomendasi
    recommendations = movie_recommendations(movie_title)

    # hitung precision
    total_recs = len(recommendations)
    relevant_recs = recommendations['genres'].apply(lambda x: is_relevant(x, target_genres)).sum()
    precision = relevant_recs / total_recs if total_recs > 0 else 0

    print(f"Precision untuk film '{movie_title}' dengan target genre {target_genres}: {precision:.2f}")

evaluate_precision_by_title('Jumanji (1995)')

"""insight :
- sistem rekomendasi dengan collaborative filtering mencapai metric evaluasi precision sebesar 100%  
"""